---
title: "Obrada podataka"
author:
  name: Luka Sikic, PhD
  affiliation: Fakultet hrvatskih studija | [OP](https://github.com/BrbanMiro/Obrada-podataka)
subtitle: 'Predavanje 6: Preuzimanje podataka sa interneta (Webscraping I)'
output:
  html_document:
    theme: flatly
    highlight: haddock
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
```

## Software podrška 

### "Vanjski" software

Za današnje pedavanje je potrebno instaliriati [SelectorGadget](https://selectorgadget.com/). SelectorGadget je Chrome ekstenzija koja omogućava jednostavno pronalaženje CSS selektora.(Instalacija je moguća preko [linka](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb).) SelectorGadget je dostupan isključivo za Chrome. U slučaju da preferirate Firefox, opcija je [ScrapeMate](https://addons.mozilla.org/en-US/firefox/addon/scrapemate/).

### R paketi 

- Novi: **rvest**, **janitor**
- Korišteni u prethodnim predavanjima: **tidyverse**, **lubridate**, **hrbrthemes**

Prisjetite se da je **rvest** automatski instaliran sa *tidyverse* paketom. Ipak, ovo je prigodan način da instalirate i učitate sve prethodno pobrojane pakete ukoliko to niste već napravili. 

```{r libs, cache=F, message=F, warning=F}
## učitaj i instaliraj pakete
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, rvest, lubridate, janitor, hrbrthemes)
## ggplot2 tema (po želji)
theme_set(hrbrthemes::theme_ipsum())
```

## Webscraping osnove

Ovo predavanje se odnosi na preuzimanje sadržaja sa web-a na lokalno računalo. Svi već imamo iskustvo sa pregledom web sadržaja u browser-u (Chrome, Firefox,...) pa razumijemo da taj sadržaj mora postojati negdje (podatci). Važno je razumjeti da postoje dva osnovna načina na koja se web sadržaj prikazuje (*engl.render*) u browser-u:

1. na strani servera (*Server-side*)
2. na strani klijenta (*Client side*)

[Pročitajte](https://www.codeconquest.com/website/client-side-vs-server-side/) za više detalje (uključujući primjere). Za potrebe ovog predavanja, glavni su sljedeći elementi: 



### 1. Server-strana

- Skripte koje "grade" web stranicu se ne izvršavaju na lokalnom računalu nego na (host) serveru
koji šalje sav HTML kod. 
  - npr. Wikipedia tablice su već popupunjene sa svim informacijama (brojevi, datumi, nazivi...) koje vidimo u browser-u. 
- Drugačije rečeno, sve informacije koje vidimo u našem browser-u su već procesuirane od strane (host) servera. 
- "Zamislite" kao da su informacije ugrađene u HTML web stranice.
- **Izazov za Webscraping:** Pronaći odgovarajuće CSS (ili Xpath) "selektore". Snalaženje u dinamičkim web stranicama (npr. "Next page" i "Show More" tabovi).
- **Ključni koncepti:** CSS, Xpath, HTML
  
### 2. Client-strana
- Web stranica sadržava prazni HTML ili CSS okvi.  
  - Npr. Moguće je da se stranica sastoji od praznog predloška tablice bez ikakvih vrijednosti.
- Kada posjetimo URL takve web stranice, naš browser šalje zahtijev (*request*) na host server.
- U slučaju da je sve u redu sa zahtjevom (*valid request*), server šalje odgovor (*response*) kao skriptu (*script*), koju naš browser izivršava i koristi kako bi popunio HTML predložak sa (specifičnim) informacijama koje smo zatražili.
- **Izazov za Webscraping:** Pronaći "API točke" može biti problematično pošto one nisu uvijek direktno vidljive.
- **Ključni koncepti:** API, API točke

U ovom predavanju ćemo proći kroz glavne razlike između ova dva pristupa i dati pregled implikacija koje svaki ima za preuzimanje web sadržaja. Važno je istaknuti da webscraping uključuje ponešto "detektivskog" posla.  Često će biti potrebno prilagoditi korake s obzirom na podatke koje želimo preuzeti, a procedure koje funkcioniraju na jednoj stranici neće nužno funkcionirati i na drugoj (ponekad neće funkcionirati ni na istoj nakon nekog vremena!). Zbog toga se je moguće reći da  webscraping podjednako uključuje umjetnost i znanost.

Pozitivna strana priče je da server-strana i client-strana dozvoljavaju preuzimanje web sadržaja. Kao što ćemo vidjeti u ostatku predavanja, preuzimanje podataka sa web stranice koja funkcionira na client-strani (API) je često jednostavnije, pogotovo kada se radi o preuzimanju veće količine podataka (*bulk*). Za webscraping vrijedi općenito pravilo: *ako vidite podatke u browseru, možete ih i preuzeti*.


### Savjet: Etička i zakonska ograničenja

Prethodna rečenica ne uzima u obzir važne etičke i zakonske aspekte preuzimanja sadržaja sa interneta. Samo zato što možete nešto preuzeti sa interneta, ne zanči da biste to i trebali učiniti. Vaša je odgovornost procijeniti da li web stranica ima zakonska ograničenja na sadržaj koji se tamo nalazi. Alati koje ćemo koristiti u ovom predavanju su uistinu moćni i mogu prenapregnuti server i izazvati poteškoće u radu ili pad web stranice. Glavna krilatice kod webscraping je stoga "budite pristojni"!


## Webscraping sa **rvest** paketom (server-strana)

Glavni paket koji se u R koristi za preuzimanje web sadržaja na strani severa je**rvest** ([link](https://rvest.tidyverse.org/)). To je jednostavan ali moćan paket za webscraping inspiriran Python-ovom **Beautiful Soup** ([link](https://www.crummy.com/software/BeautifulSoup/)) platformom, ali uz dodatne tidyverse funkcionalnosti :-). **rvest** je osmišljen za rad sa stranicama koje su procesuirane na srani severa i zbog toga zahtijeva razumijevanje CSS selektora...pa pogledajmo što je to točno.

### CSS i SelectorGadget

Za detaljnije informacije o [CSS](https://developer.mozilla.org/en-US/docs/Learn/CSS/Introduction_to_CSS/How_CSS_works) (i.e Cascading Style Sheets) i [SelectorGadget](http://selectorgadget.com/) pročitajte više na interentu. Ukratko, CSS je jezik koji određuje izled HTML dokumenata (uključujući i web stranice). To postiže tako što omogućuje browseru skup pravila za prikaz koja se formiraju na osnovi: 

1. _Properties._ CSS svojstva određuju **kako** će se nešto prkazati. To su npr. fontovi, stilovi, boje, širina stranice itd. 
2. _Selectors._ CSS selektori odrđuju **što** što će se prikazivati. Oni definirajz pravila koja se pripisuju pojedinim elementima stranice. Npr Tekstualni elementi definirani kao ".h1" (i.e. naslovi) su obično veći i naglašeniji nego elementi definirani kao ".h2" (i.e. podnaslovi).

Za preuzimanje sadržaja sa web stranice je bitno identificirati CSS selektore sadržaja koji želimo skinuti jer tako izoliramo djelove stranice od interesa. Upravo tu dolazi do izražaja korisnost *SelectorGadget-a*. U ovom predavanj ućemo proći kroz primjer korištenja *SelectorGadget-a* no preporučljivo je pogledati [vignette](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html) prije nastavka.

## Praktični primjer: Sprint na 100m (Wikipedia)

Stavimo sve ovo u praktični kontekst. Želimo preuzeti podatke sa Wikipedia stranice [**Men's 100 metres world record progression**](http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression). 

Prvo, otvorite ovu stranicu u vašem browser-u. Upoznajte se sa strukturom stranice: Kakve objekte stranica sadrži? Koliko ima tablica? Da li tablice imaju iste kolone? Kakvi su rasponi redova i kolona? itd.

Sada kada ste se upoznali sa strukturom stranice, učitajte cijelu stranicu u R koristeći `rvest::read_html()` funkciju

```{r m100_read_html}
# library(rvest) ## već učitano
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression") 
m100
```

Kao što vidite, ovo je [XML](https://en.wikipedia.org/wiki/XML) dokument^[XML je kratica za Extensible Markup Language i jedan je od glavnih jezika za formatiranje web stranica.] koji sadrži sve potrebno za procesuiranje Wikipedia stranice. To je otprilike kao da promatrate cjelokupni LaTeX ili .pdf dokument (specifikacije, formule, itd.), a želite preuzeti samo jednu tablicu ili dio poglavlja.

### Tablica 1: Pred-IAAF era (1881--1912)

Pokušajmo izolirati prvu tablicu sa naslovom [Unofficial progression before the IAAF](https://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression#Unofficial_progression_before_the_IAAF). Kao što je objašnjeno u rvest vignette, možemo koristiti funkciju `rvest::html_nodes()` kako bismo izolirali i preuzeli ovu tablicu iz ostatka HTML dokumenta kroz specifikaciju odggovarajućih CSS selektor.Potom je potrebno pretvoriti objekt u data frame koristeći `rvest::html_table()` funkciju. Preporuča se korištenje `fill=TRUE` opcije u ovom slučaju, jer će se u suprotnom javiti problemi sa formatiranjem redova zbog razmaka u Wiki tablici. 

Koristiti ćemo [SelectorGadget](http://selectorgadget.com/) za identifikaciju CSS selektora. U ovom slučaju je riječ o "div+ .wikitable :nth-child(1)", pa pogledajmo kako to funkcionira.

```{r m100_read_table_e, error=TRUE}
m100 %>%
  html_nodes("div+ .wikitable :nth-child(1)") %>%
  html_table(fill=TRUE) 
```

Nešto nije u redu...!? Dobili smo error. Bez da ulazimo u detalje, valja naglasiti da je SelectorGadget ponekad neprecizan....riječ je o izvrsnom alatu koji uglavnom radi dobro. Ipak, ponekad ono što izgleda kao dobar selektor (i.e. naglašeno žuto) nije ono što točno tražimo. Ovo je prikazano namjerno radi skretanja pažnje na potencijalne probleme koji se mogu javiti pri korištenu SelectorGadget. Ponovno valja istaknuti: Webscraping je u jednakoj mjeri umjetnost i znanost!

Na sreću, postoji i precizniji način određivanja točnog selektora,a odnosi se na korištenje "inspect web element" opcije koju ima [većina modernih browser-a](https://www.lifewire.com/get-inspect-element-tool-for-browser-756549). U ovom slučaju koristimo (**Ctrl+Shift+I**, ili desni klik miša i izaberi "Inspect"). Potom ćemo proći kroz *source elemente* dok Chrome ne istakne tablicu koja nas zanima. Potom opet desni klik miša i izaberite **Copy -> Copy selector**. Pogledajte opisanu proceduru:

![](../Foto/inspect100m.gif)

Koristeći ovu metodu dobijemo selektor "#mw-content-text > div > table:nth-child(8)". Pogledajmo da li će opvaj put sve funkcionirati bez error-a. Ponovno ćemo koristiti `rvest::html_table(fill=TRUE)` funkciju za prebacivanje tablice u data frame.

```{r m100_read_table, dependson=m100, echo=1:2}
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")

m100 %>%
  html_nodes("#mw-content-text > div > table:nth-child(8)") %>%
  html_table(fill=TRUE) 
```

Sjajno, čini se da sve radi! Sada ćemo sve pripisati novom objektu `pre_iaaf` i provjeriti objektnu klasu (class).

```{r pre_iaaf_1}
pre_iaaf <-
  m100 %>%
  html_nodes("#mw-content-text > div > table:nth-child(8)") %>%
  html_table(fill=TRUE) 
class(pre_iaaf)
```

Izgleda da smo dobili list-u! Pretvorimo taj objekt  *stvarno* u data frame. To je moguće učiniti na više načina. U ovom slučaju ćemo koristiti `dplyr::bind_rows()` funkciju. Riječ je o izvrsnom načinu za pretvaranje više list-a u jedan data frame.^[Ovu funkciju ćemo susresti još nekoliko puta u daljem tijeku kolegija.]

```{r pre_iaaf_2, message = F}
## pretvori list-u u data_frame
# pre_iaaf <- pre_iaaf[[1]] ## također moguće
# library(tidyverse) ## A++već učitano
pre_iaaf <- 
  pre_iaaf %>%
  bind_rows() %>%
  as_tibble()
pre_iaaf
```

Sada je potrebno urediti nazive varijabli (kolona)...ovdje koristimo `janitor::clean_names()` funkciju, koja je napravljena isključivo za tu namjenu. (Q: Na koji drugi način se to može učiniti?)

```{r pre_iaaf_3}
# library(janitor) ## učitano
pre_iaaf <-
  pre_iaaf %>%
  clean_names()
pre_iaaf
```

Primijetimo da postoji još nešto "nereda" u zapisima Isaac-a Westergren-a u Gävle, Sweden. Mogli bismo to popraviti na nekoliko načina. U ovom slučaju ćemo pokušati pretvoriti "athlete" varijablu  numeričkui zamijeniti je sa prethodnom vrijednosti.

```{r pre_iaaf_4}
pre_iaaf <-
  pre_iaaf %>%
  mutate(athlete = ifelse(is.na(as.numeric(athlete)), athlete, lag(athlete)))
```

Na kraju je potrebno urediti "date" varijablu tako da R može prepoznati string vrijednosti kao datum.

```{r pre_iaaf_5, message=F}
# library(lubridate) ## već učitano
pre_iaaf <-
  pre_iaaf %>%
  mutate(date = mdy(date))
pre_iaaf
```

Sada imamo čisti data frame i mogli bismo napraviti vizualizaciju pre-IAAF podataka. To ćemo ipak malo odgoditi dok ne preuzmemo ostatak tablica sa stranice...



### Tablica 2: Pred-automatska era (1912--1976)

Yapo;nimo sa drugom tablicom.
```{r iaaf_76_1, dependson=m100, echo=1:2}
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")

iaaf_76 <-
  m100 %>%
  html_nodes("#mw-content-text > div > table:nth-child(14)") %>%
  html_table(fill=TRUE) 
## Pretvori list-u u data_frame i uredi nazve varijabli (kolona)
iaaf_76 <- 
  iaaf_76 %>%
  bind_rows() %>%
  as_tibble() %>%
  clean_names()
```

Potrebno je popuniti vrijednosti koje nedostaju (NA!) za athlete varijablu (potrebna malo drugačija procedura nego u prošloj tablici --- Zašto?) i urediti datume. 

```{r iaaf_76_2, dependson=iaaf_76}
iaaf_76 <-
  iaaf_76 %>%
  mutate(athlete = ifelse(athlete=="", lag(athlete), athlete)) %>%
  mutate(date = mdy(date)) 
```

Čini se da su neki datumi ostali u čudnom zapisu zbog loših podataka (jednaki datumi za različite dane) u tablici:

```{r iaaf_76_3, dependson=iaaf_76}
iaaf_76 %>% tail(20)
```

Problem ćemo riješiti tako da vrijednosti popunimo sa prethohdnim realizacijama (lag-ovima). Prvo je potrebno isprobati:

```{r iaaf_76_4, dependson=iaaf_76}
iaaf_76 %>%
  mutate(date = ifelse(is.na(date), lag(date), date))
```

Izgleda da su datumi postali numerička varijabla (brojevi). Razlog je korištenje (probajte pronaći na Google) base R funkcije `ifelse()`. U ovom će slučaju biti bolja tidyverse ekvivalentna funkcija, i.e. `if_else()`.

```{r iaaf_76_5, dependson=iaaf_76}
iaaf_76 <-
  iaaf_76 %>%
  mutate(date = if_else(is.na(date), lag(date), date))
iaaf_76
```


### Tablica 3: Moderna era (1977 nadalje)

Zadnja tablica također sadržava neke specifičnosti vezano uz razmake u redovima i dr. Probajte sami izvršiti sljedeći kod! Ovdje sve izvršavamo u jednom komadu (*engl. chunk*) koda:

```{r iaaf, dependson=m100}
iaaf <-
  m100 %>%
  html_nodes("#mw-content-text > div > table:nth-child(19)") %>%
  html_table(fill=TRUE) 
## Pretvori list-u u data_frame i uredi nazve varijabli (kolona)
iaaf <- 
  iaaf %>%
  bind_rows() %>%
  as_tibble() %>%
  clean_names()
## Uredi datum. 
iaaf <-
  iaaf %>%
  mutate(date = mdy(date))
## Usain Bolt  je pripisan Asafa Powell-u zbog
## razmaka u Wikipedia redovima (ista zemlja, i dr.). E.g.
iaaf %>% tail(8)
## Popravljeno
iaaf <-
  iaaf %>%
  mutate(
    athlete = ifelse(athlete==nationality, NA, athlete),
    athlete = ifelse(!is.na(as.numeric(nationality)), NA, athlete),
    athlete = ifelse(nationality=="Usain Bolt", nationality, athlete),
    nationality = ifelse(is.na(athlete), NA, nationality),
    nationality = ifelse(athlete==nationality, NA, nationality)
    ) %>%
  fill(athlete, nationality)
```

### Kombinirane tablice

Povežimo odvojena razdoblja u jedan data frame. Ponovno ćemo koristiti funkciju `dplyr:: bind_rows()` i zadržati samo zajedničke varijable. Također ćemo dodati varijablu (kolonu) koja se refeira na razdoblje za koje su zabilježeni rezultati. 

```{r wr100, dependson=pre_iaaf, dependson=iaaf_76, dependson=iaaf}
wr100 <- 
  bind_rows(
    pre_iaaf %>% select(time, athlete, nationality:date) %>% mutate(era = "IAAF"),
    iaaf_76 %>% select(time, athlete, nationality:date) %>% mutate(era = "Pred-automatska"),
    iaaf %>% select(time, athlete, nationality:date) %>% mutate(era = "Moderna")
  )
wr100
```

Vizualizaciju podataka...

```{r wr100_plot, dependson=wr100, warning=F}
wr100 %>%
  ggplot(aes(x=date, y=time, col=fct_reorder2(era, date, time))) + 
  geom_point(alpha = 0.7) +
  labs(
    title = "Evolucija svjetskog rekorda -- Sprint na 100m",
    x = "Datum", y = "Postignuće (100m u sek)",
    caption = "Izvor: Wikipedia"
    ) +
  theme(legend.title = element_blank()) ## Makni legendu
```


## Sažetak

- Web sadržaj je procesuiran na strani 1) servera ili 2) klijenta
- Za preuzimanje sadržaja na strani servera, potrebno je identificirati CSS selektore
- Selektore (CSS) možemo identificirati pomoću SelectorGadget-a ili korz *inspekciju* elemenata u browser-u
- Koristi se `rvest` paket za učitavanje HTML dokumenta u R i parsanje nodova od interesa. 
- tipični pristup rada uključuje:`read_html(URL) %>% html_nodes(CSS_SELECTORS) %>% html_table()`.
  - Druge funkcije mogu biti potrebne ovisno o vrsti podataka koje preuzimamo (npr. `?html_text`).
- Samo zato što *možete* scrapati neku stranicu, ne znači i da *trebate*  (i.e. etički i zakonski aspekti).
- Webscraping je u jednakoj mjeri umjetnost kao i znanost. Budite spremni na dosta eksperimentiranja i  čišćenja podataka.
- Nastavak predavanja: Webscraping: (2) Client-strana i API.


##Doddatni resursi i vježba

Probajte koristiti novo-stečene `rvest` vještine na nekom od (mnogih) online tutoriala. Dodatno valja istakunti:

### Web manire i bonton

Smomenuli smo princip  "lijepog ponašanja" na web-u...ovdje vrijedi istaknuti **polite** paket ([link](https://github.com/dmi3kno/polite)). Paket omogućava korisne alate u maniri dobrog ponašanja na web-u poput provjere dopuštenja i opterećenja stranice sa koje preuzimamo sadržaj. Paket se također nadopunjuje sa **rvest** pristupom koji smo prikazali u predavanju. 

### Modeliranje i predviđanje

Preuzeti podatci predstavljaju dobru osnovu za statističku analizu pa ih je dobro promotriti u tom kontekstu. kako biste modelirali napredak u svjetskim sprint rekordima na 100m? Zamislite da želite predvidjeti današnji svjetski rekord u 2005. godini! Kako bi se predviđanje odnosilo na aktualni rekord iz 2009. godine (i.e. Usain Bolt, 9.58 sec)?  Kako biste to interpretirali?

*Savjet: Pogledajte `?broom::tidy()`funkciju za ekstrakciju regresijskih koeficijenata u prikladnom data frame objektu. Već smo vidjeli `geom_smooth()` funkciju u predavanju o vizualizaciji podataka. Za ideje o vizualizaciji predviđanja pogledajte [Poglavlje 23](http://r4ds.had.co.nz/model-basics.html#visualising-models)  R4DS knjige, ili [Poglavlje 6.4](http://socviz.co/modeling.html#generate-predictions-to-graph) SocViz knjige. Razmotrite `base::predict()` funkcij. Alternativno koristite tidyverse's `modelr` paket.*

